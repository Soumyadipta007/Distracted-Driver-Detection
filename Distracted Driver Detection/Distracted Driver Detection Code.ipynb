{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory='C:/Users/User/Python/Projects/Distracted Driver Detection/Data/train/'\n",
    "test_directory='C:/Users/User/Python/Projects/Distracted Driver Detection/Data/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For training the model, I am first dividing the Training Data on 8:2 ratio.\n",
    "# Training the model on this 80% Data at first and then checking the accuracy on the remaining 20% by comparing it with its actual output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating two separate folders for Training and Testing purposes having the same folder structure as Input Training Data and then copying the files in 8:2 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Names: c0 c1 c2 c3 c4 c5 c6 c7 c8 c9 "
     ]
    }
   ],
   "source": [
    "c=0\n",
    "data={}\n",
    "# os.listdir() method in python is used to get the list of all files and directories in the specified directory. \n",
    "for (filenames) in os.listdir(train_directory):\n",
    "\n",
    "    for imgfile in os.listdir(train_directory+ filenames):\n",
    "\n",
    "        if filenames in data:\n",
    "            data[filenames].append(imgfile)\n",
    "        else:\n",
    "            data[filenames]=[imgfile]\n",
    "\n",
    "print(\"Category Names:\",end=\" \")\n",
    "for i in data:\n",
    "    print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating separate folders so that training data can be divided for model training\n",
    "categories_list=list(data.keys())\n",
    "os.mkdir('master_data')\n",
    "os.mkdir('master_data/training')\n",
    "os.mkdir('master_data/testing')\n",
    "for category in categories_list:\n",
    "    os.mkdir(os.path.join('master_data/training/',category))\n",
    "    os.mkdir(os.path.join('master_data/testing/',category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping 80% training data in master_data/training and 20% in master_data/testing.\n",
    "# This 20% data will be later used to check my model accuracy.\n",
    "split_size=0.8\n",
    "for category,images in data.items():\n",
    "    train_size=int(split_size*len(images))\n",
    "    train_images=images[:train_size]\n",
    "    test_images=images[train_size:]\n",
    "    for image in train_images:\n",
    "        source=os.path.join('Data/train',category,image)\n",
    "        dest=os.path.join('Code/master_data/training',category,image)\n",
    "        copyfile(source,dest)\n",
    "    for image in test_images:\n",
    "        source=os.path.join('Data/train',category,image)\n",
    "        dest=os.path.join('Code/master_data/testing',category,image)\n",
    "        copyfile(source,dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 64)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 25, 25, 256)       131328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 512)       524800    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               9216500   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 9,911,366\n",
      "Trainable params: 9,911,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating the CNN Model.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(100,100,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=512, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and computing the values of the parameters of the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17934 images belonging to 10 classes.\n",
      "Found 4490 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Giving the directory paths to Image Data Generator.\n",
    "train_dir='master_data/training'\n",
    "test_dir='master_data/testing'\n",
    "train_datagen=ImageDataGenerator(rescale=1.0/255)\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(100,100),class_mode='categorical',batch_size=100)\n",
    "test_datagen=ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,target_size=(100,100),class_mode='categorical',batch_size=100)\n",
    "\n",
    "es=EarlyStopping(monitor='val_acc',patience=2,min_delta=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "180/180 [==============================] - 325s 2s/step - loss: 1.2140 - acc: 0.5686 - val_loss: 0.2528 - val_acc: 0.9298\n",
      "Epoch 2/5\n",
      "180/180 [==============================] - 326s 2s/step - loss: 0.2785 - acc: 0.9142 - val_loss: 0.1117 - val_acc: 0.9690\n",
      "Epoch 3/5\n",
      "180/180 [==============================] - 327s 2s/step - loss: 0.1489 - acc: 0.9553 - val_loss: 0.0626 - val_acc: 0.9833\n",
      "Epoch 4/5\n",
      "180/180 [==============================] - 345s 2s/step - loss: 0.1026 - acc: 0.9695 - val_loss: 0.0525 - val_acc: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1926d7a5a48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80% of Training data is fitted. We can see the accuracy for testing data as it is provided in validation_data parameter\n",
    "model.fit_generator(train_generator,validation_data=test_generator,epochs=5,verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the accuracy to determine model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 31s 694ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict_generator(test_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05249389924315943\n",
      "Accuracy:  0.98641425\n"
     ]
    }
   ],
   "source": [
    "# Getting the loss and accuracy on the 20% training data which we kept for testing purposes\n",
    "loss,accuracy=model.evaluate_generator(test_generator)\n",
    "print(\"Loss: \",loss)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Testing Data need to fit the whole Training Data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen_complete=ImageDataGenerator(rescale=1.0/255)\n",
    "train_generator_complete=train_datagen_complete.flow_from_directory(train_directory,target_size=(100,100),class_mode='categorical',batch_size=100)\n",
    "es=EarlyStopping(monitor='val_acc',patience=2,min_delta=0.02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinitializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 100, 100, 64)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 50, 50, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 25, 25, 256)       131328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 512)       524800    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               9216500   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 9,911,366\n",
      "Trainable params: 9,911,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# need to reinitialize the model before the whole training data fitting\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(100,100,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=512, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "224/225 [============================>.] - ETA: 2s - loss: 1.1620 - acc: 0.6026WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "225/225 [==============================] - 548s 2s/step - loss: 1.1583 - acc: 0.6038\n",
      "Epoch 2/5\n",
      "224/225 [============================>.] - ETA: 1s - loss: 0.2006 - acc: 0.9402WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "225/225 [==============================] - 370s 2s/step - loss: 0.2003 - acc: 0.9403\n",
      "Epoch 3/5\n",
      "224/225 [============================>.] - ETA: 1s - loss: 0.1053 - acc: 0.9693WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "225/225 [==============================] - 372s 2s/step - loss: 0.1055 - acc: 0.9691\n",
      "Epoch 4/5\n",
      "224/225 [============================>.] - ETA: 1s - loss: 0.0698 - acc: 0.9788WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "225/225 [==============================] - 372s 2s/step - loss: 0.0696 - acc: 0.9789\n",
      "Epoch 5/5\n",
      "224/225 [============================>.] - ETA: 1s - loss: 0.0579 - acc: 0.9836WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "225/225 [==============================] - 371s 2s/step - loss: 0.0577 - acc: 0.9837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x192002ad748>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the whole training data on the CNN model\n",
    "model.fit_generator(train_generator_complete,epochs=5,verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The folder structure given for the Testing Data is not compatible with Image Data Generator. Need to create a new folder structure so that Data can be fed to the Image Data Generator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=[]\n",
    "for (filenames) in os.listdir(test_directory):\n",
    "    test_images.append(filenames)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('master_data/Unknown_Image_Testing')\n",
    "os.mkdir('master_data/Unknown_Image_Testing/Images')\n",
    "\n",
    "for image in test_images:\n",
    "    source=os.path.join(test_directory,image)\n",
    "    dest=os.path.join('master_data/Unknown_Image_Testing/Images/',image)    \n",
    "    copyfile(source,dest)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory='master_data/Unknown_Image_Testing/',\n",
    "    target_size=(100,100),\n",
    "    batch_size=100,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the output for the images of the Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798/798 [==============================] - 627s 785ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting the output for the testing data i.e whether the drivers were distracted or not.\n",
    "pred=model.predict_generator(test_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79726, 10)\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the output in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>SAFE_DRIVING</th>\n",
       "      <th>TEXTING_RIGHT</th>\n",
       "      <th>TALKING_PHONE_RIGHT</th>\n",
       "      <th>TEXTING_LEFT</th>\n",
       "      <th>TALKING_PHONE_LEFT</th>\n",
       "      <th>OPERATING_RADIO</th>\n",
       "      <th>DRINKING</th>\n",
       "      <th>REACHING_BEHIND</th>\n",
       "      <th>HAIR_AND_MAKEUP</th>\n",
       "      <th>TALKING_TO_PASSENGER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [img, SAFE_DRIVING, TEXTING_RIGHT, TALKING_PHONE_RIGHT, TEXTING_LEFT, TALKING_PHONE_LEFT, OPERATING_RADIO, DRINKING, REACHING_BEHIND, HAIR_AND_MAKEUP, TALKING_TO_PASSENGER]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'img':[],'SAFE_DRIVING':[], 'TEXTING_RIGHT':[],'TALKING_PHONE_RIGHT':[], \n",
    "                   'TEXTING_LEFT':[], 'TALKING_PHONE_LEFT':[],'OPERATING_RADIO':[], 'DRINKING':[], \n",
    "                   'REACHING_BEHIND':[], 'HAIR_AND_MAKEUP':[], 'TALKING_TO_PASSENGER':[]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in pred:\n",
    "    df = df.append(  #Append rows of other to the end of caller, returning a new object.\n",
    "            {\n",
    "                'img':test_images[c],\n",
    "                'SAFE_DRIVING':round(i[0],2), \n",
    "                'TEXTING_RIGHT':round(i[1],2),\n",
    "                'TALKING_PHONE_RIGHT':round(i[2],2),\n",
    "                'TEXTING_LEFT':round(i[3],2),\n",
    "                'TALKING_PHONE_LEFT':round(i[4],2),\n",
    "                'OPERATING_RADIO':round(i[5],2),\n",
    "                'DRINKING':round(i[6],2),\n",
    "                'REACHING_BEHIND':round(i[7],2),\n",
    "                'HAIR_AND_MAKEUP':round(i[8],2),\n",
    "                'TALKING_TO_PASSENGER':round(i[9],2)\n",
    "                \n",
    "            },\n",
    "            ignore_index=True  #If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
    "              )\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>SAFE_DRIVING</th>\n",
       "      <th>TEXTING_RIGHT</th>\n",
       "      <th>TALKING_PHONE_RIGHT</th>\n",
       "      <th>TEXTING_LEFT</th>\n",
       "      <th>TALKING_PHONE_LEFT</th>\n",
       "      <th>OPERATING_RADIO</th>\n",
       "      <th>DRINKING</th>\n",
       "      <th>REACHING_BEHIND</th>\n",
       "      <th>HAIR_AND_MAKEUP</th>\n",
       "      <th>TALKING_TO_PASSENGER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>img_99994.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79722</th>\n",
       "      <td>img_99995.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>img_99996.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>img_99998.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79725</th>\n",
       "      <td>img_99999.jpg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79726 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img  SAFE_DRIVING  TEXTING_RIGHT  TALKING_PHONE_RIGHT  \\\n",
       "0           img_1.jpg          0.00           0.00                 0.00   \n",
       "1          img_10.jpg          0.00           0.00                 0.00   \n",
       "2         img_100.jpg          0.55           0.15                 0.00   \n",
       "3        img_1000.jpg          0.00           0.00                 0.00   \n",
       "4      img_100000.jpg          0.00           0.00                 0.00   \n",
       "...               ...           ...            ...                  ...   \n",
       "79721   img_99994.jpg          0.00           0.12                 0.15   \n",
       "79722   img_99995.jpg          0.00           0.00                 0.00   \n",
       "79723   img_99996.jpg          0.00           0.00                 0.00   \n",
       "79724   img_99998.jpg          0.00           0.00                 0.00   \n",
       "79725   img_99999.jpg          0.00           0.00                 0.00   \n",
       "\n",
       "       TEXTING_LEFT  TALKING_PHONE_LEFT  OPERATING_RADIO  DRINKING  \\\n",
       "0               0.0                0.00              1.0      0.00   \n",
       "1               0.0                0.00              1.0      0.00   \n",
       "2               0.0                0.00              0.0      0.00   \n",
       "3               0.0                0.00              0.0      0.08   \n",
       "4               0.0                0.99              0.0      0.00   \n",
       "...             ...                 ...              ...       ...   \n",
       "79721           0.0                0.00              0.0      0.00   \n",
       "79722           1.0                0.00              0.0      0.00   \n",
       "79723           0.0                0.99              0.0      0.01   \n",
       "79724           0.0                0.00              0.0      1.00   \n",
       "79725           0.0                0.00              1.0      0.00   \n",
       "\n",
       "       REACHING_BEHIND  HAIR_AND_MAKEUP  TALKING_TO_PASSENGER  \n",
       "0                 0.00             0.00                  0.00  \n",
       "1                 0.00             0.00                  0.00  \n",
       "2                 0.00             0.00                  0.29  \n",
       "3                 0.00             0.92                  0.00  \n",
       "4                 0.00             0.00                  0.00  \n",
       "...                ...              ...                   ...  \n",
       "79721             0.57             0.15                  0.00  \n",
       "79722             0.00             0.00                  0.00  \n",
       "79723             0.00             0.01                  0.00  \n",
       "79724             0.00             0.00                  0.00  \n",
       "79725             0.00             0.00                  0.00  \n",
       "\n",
       "[79726 rows x 11 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally storing the output in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Test_Data_Output.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
